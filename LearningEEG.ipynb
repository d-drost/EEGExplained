{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "31881e3f-539e-4cc2-87f9-22970ee785be",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "DigMontage is only a subset of info. There are 33 channel positions not present in the DigMontage. The channels missing from the montage are:\n\n['FC5', 'FC1', 'FC2', 'FC6', 'T7', 'T8', 'CP5', 'CP1', 'CP2', 'CP6', 'P7', 'P8', 'POz', 'AF7', 'AF3', 'AF4', 'AF8', 'FC3', 'FCz', 'FC4', 'CP3', 'CPz', 'CP4', 'PO5', 'PO3', 'PO4', 'PO6', 'FT7', 'FT8', 'TP7', 'TP8', 'PO7', 'PO8'].\n\nConsider using inst.rename_channels to match the montage nomenclature, or inst.set_channel_types if these are not EEG channels, or use the on_missing parameter if the channel positions are allowed to be unknown in your analyses.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m x \u001b[38;5;241m=\u001b[39m raw\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m----> 2\u001b[0m x\u001b[38;5;241m.\u001b[39mset_montage(make_standard_montage(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstandard_alphabetic\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m      3\u001b[0m x\u001b[38;5;241m.\u001b[39mplot_sensors(ch_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meeg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m<decorator-gen-22>:12\u001b[0m, in \u001b[0;36mset_montage\u001b[0;34m(self, montage, match_case, match_alias, on_missing, verbose)\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/eeg/lib/python3.11/site-packages/mne/_fiff/meas_info.py:422\u001b[0m, in \u001b[0;36mMontageMixin.set_montage\u001b[0;34m(self, montage, match_case, match_alias, on_missing, verbose)\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchannels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmontage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _set_montage\n\u001b[1;32m    421\u001b[0m info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, Info) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\n\u001b[0;32m--> 422\u001b[0m _set_montage(info, montage, match_case, match_alias, on_missing)\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/eeg/lib/python3.11/site-packages/mne/channels/montage.py:1250\u001b[0m, in \u001b[0;36m_set_montage\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1239\u001b[0m are_is \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mare\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pl \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1240\u001b[0m missing_coord_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1241\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDigMontage is only a subset of info. There \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mare_is\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1242\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(missing)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m channel position\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not present in the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1248\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mposition\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mare_is\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m allowed to be unknown in your analyses.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1249\u001b[0m )\n\u001b[0;32m-> 1250\u001b[0m _on_missing(on_missing, missing_coord_msg)\n\u001b[1;32m   1252\u001b[0m \u001b[38;5;66;03m# set ch coordinates and names from digmontage or nan coords\u001b[39;00m\n\u001b[1;32m   1253\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ii \u001b[38;5;129;01min\u001b[39;00m missing:\n",
      "File \u001b[0;32m~/miniconda3/envs/eeg/lib/python3.11/site-packages/mne/utils/check.py:1219\u001b[0m, in \u001b[0;36m_on_missing\u001b[0;34m(on_missing, msg, name, error_klass)\u001b[0m\n\u001b[1;32m   1217\u001b[0m on_missing \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m on_missing \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarning\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m on_missing\n\u001b[1;32m   1218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m on_missing \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1219\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_klass(msg)\n\u001b[1;32m   1220\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m on_missing \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1221\u001b[0m     warn(msg)\n",
      "\u001b[0;31mValueError\u001b[0m: DigMontage is only a subset of info. There are 33 channel positions not present in the DigMontage. The channels missing from the montage are:\n\n['FC5', 'FC1', 'FC2', 'FC6', 'T7', 'T8', 'CP5', 'CP1', 'CP2', 'CP6', 'P7', 'P8', 'POz', 'AF7', 'AF3', 'AF4', 'AF8', 'FC3', 'FCz', 'FC4', 'CP3', 'CPz', 'CP4', 'PO5', 'PO3', 'PO4', 'PO6', 'FT7', 'FT8', 'TP7', 'TP8', 'PO7', 'PO8'].\n\nConsider using inst.rename_channels to match the montage nomenclature, or inst.set_channel_types if these are not EEG channels, or use the on_missing parameter if the channel positions are allowed to be unknown in your analyses."
     ]
    }
   ],
   "source": [
    "x = raw.copy()\n",
    "x.set_montage(make_standard_montage(\"standard_alphabetic\"))\n",
    "x.plot_sensors(ch_type=\"eeg\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4261999d-cdc5-4d36-8e10-9ae84155f7c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /home/dorian/PycharmProjects/internship/learning_eeg/../sub400/400MNE.fdt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15627/778817812.py:3: RuntimeWarning: Estimated head radius (0.0 cm) is below the 3rd percentile for infant head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
      "  raw = read_raw_eeglab(\"../sub400/400MNE.set\")\n",
      "/tmp/ipykernel_15627/778817812.py:5: RuntimeWarning: The unit for channel(s) AUX1, AUX2, AUX3, AUX4, BIP2, BIP3, BIP4, M1, M2 has changed from V to NA.\n",
      "  raw.set_channel_types({\"BIP1\":\"eog\",\"BIP2\":\"misc\",\"BIP3\":\"misc\",\"BIP4\":\"misc\", \"AUX1\":\"misc\",\"AUX2\":\"misc\",\"AUX3\":\"misc\",\"AUX4\":\"misc\", \"M1\":\"misc\", \"M2\":\"misc\"})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">\n",
       "    const toggleVisibility = (className) => {\n",
       "\n",
       "  const elements = document.querySelectorAll(`.${className}`)\n",
       "\n",
       "  elements.forEach(element => {\n",
       "    if (element.classList.contains('repr-section-header')) {\n",
       "      // Don't collapse the section header row.\n",
       "       return\n",
       "    }\n",
       "    if (element.classList.contains('repr-element-collapsed')) {\n",
       "      // Force a reflow to ensure the display change takes effect before removing the class\n",
       "      element.classList.remove('repr-element-collapsed')\n",
       "      element.offsetHeight // This forces the browser to recalculate layout\n",
       "      element.classList.remove('repr-element-faded')\n",
       "    } else {\n",
       "      // Start transition to hide the element\n",
       "      element.classList.add('repr-element-faded')\n",
       "      element.addEventListener('transitionend', handler = (e) => {\n",
       "        if (e.propertyName === 'opacity' && getComputedStyle(element).opacity === '0.2') {\n",
       "          element.classList.add('repr-element-collapsed')\n",
       "          element.removeEventListener('transitionend', handler)\n",
       "        }\n",
       "      });\n",
       "    }\n",
       "  });\n",
       "\n",
       "  // Take care of button (adjust caret)\n",
       "  const button = document.querySelectorAll(`.repr-section-header.${className} > th.repr-section-toggle-col > button`)[0]\n",
       "  button.classList.toggle('collapsed')\n",
       "\n",
       "  // Take care of the tooltip of the section header row\n",
       "  const sectionHeaderRow = document.querySelectorAll(`tr.repr-section-header.${className}`)[0]\n",
       "  sectionHeaderRow.classList.toggle('collapsed')\n",
       "  sectionHeaderRow.title = sectionHeaderRow.title === 'Hide section' ? 'Show section' : 'Hide section'\n",
       "}\n",
       "</script>\n",
       "\n",
       "<style type=\"text/css\">\n",
       "    table.repr.table.table-hover.table-striped.table-sm.table-responsive.small {\n",
       "  /* Don't make rows wider than they need to be. */\n",
       "  display: inline;\n",
       "}\n",
       "\n",
       "table > tbody > tr.repr-element > td {\n",
       "  /* Apply a tighter layout to the table cells. */\n",
       "  padding-top: 0.1rem;\n",
       "  padding-bottom: 0.1rem;\n",
       "  padding-right: 1rem;\n",
       "}\n",
       "\n",
       "table > tbody > tr > td.repr-section-toggle-col {\n",
       "  /* Remove background and border of the first cell in every row\n",
       "     (this row is only used for the collapse / uncollapse caret)\n",
       "\n",
       "     TODO: Need to find a good solution for VS Code that works in both\n",
       "           light and dark mode. */\n",
       "  border-color: transparent;\n",
       "  --bs-table-accent-bg: transparent;\n",
       "}\n",
       "\n",
       "tr.repr-section-header {\n",
       "  /* Remove stripes from section header rows */\n",
       "  background-color: transparent;\n",
       "  border-color: transparent;\n",
       "  --bs-table-striped-bg: transparent;\n",
       "  cursor: pointer;\n",
       "}\n",
       "\n",
       "tr.repr-section-header > th {\n",
       "  text-align: left !important;\n",
       "  vertical-align: middle;\n",
       "}\n",
       "\n",
       ".repr-element, tr.repr-element > td {\n",
       "  opacity: 1;\n",
       "  text-align: left !important;\n",
       "}\n",
       "\n",
       ".repr-element-faded {\n",
       "  transition: 0.3s ease;\n",
       "  opacity: 0.2;\n",
       "}\n",
       "\n",
       ".repr-element-collapsed {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "/* Collapse / uncollapse button and the caret it contains. */\n",
       ".repr-section-toggle-col button {\n",
       "  cursor: pointer;\n",
       "  width: 1rem;\n",
       "  background-color: transparent;\n",
       "  border-color: transparent;\n",
       "}\n",
       "\n",
       "span.collapse-uncollapse-caret {\n",
       "  width: 1rem;\n",
       "  height: 1rem;\n",
       "  display: block;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: left;\n",
       "  background-size: contain;\n",
       "}\n",
       "\n",
       "/* The collapse / uncollapse carets were copied from the free Font Awesome collection and adjusted. */\n",
       "\n",
       "/* Default to black carets for light mode */\n",
       ".repr-section-toggle-col > button.collapsed > span.collapse-uncollapse-caret {\n",
       "  background-image: url('data:image/svg+xml;charset=utf8,<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 256 512\"><!--!Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.--><path fill=\"black\" d=\"M246.6 278.6c12.5-12.5 12.5-32.8 0-45.3l-128-128c-9.2-9.2-22.9-11.9-34.9-6.9s-19.8 16.6-19.8 29.6l0 256c0 12.9 7.8 24.6 19.8 29.6s25.7 2.2 34.9-6.9l128-128z\"/></svg>');\n",
       "}\n",
       "\n",
       ".repr-section-toggle-col\n",
       "  > button:not(.collapsed)\n",
       "  > span.collapse-uncollapse-caret {\n",
       "  background-image: url('data:image/svg+xml;charset=utf8,<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 320 512\"><!--!Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.--><path fill=\"black\" d=\"M137.4 374.6c12.5 12.5 32.8 12.5 45.3 0l128-128c9.2-9.2 11.9-22.9 6.9-34.9s-16.6-19.8-29.6-19.8L32 192c-12.9 0-24.6 7.8-29.6 19.8s-2.2 25.7 6.9 34.9l128 128z\"/></svg>');\n",
       "}\n",
       "\n",
       "/* Use white carets for dark mode */\n",
       "@media (prefers-color-scheme: dark) {\n",
       "  .repr-section-toggle-col > button.collapsed > span.collapse-uncollapse-caret {\n",
       "    background-image: url('data:image/svg+xml;charset=utf8,<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 256 512\"><!--!Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.--><path fill=\"white\" d=\"M246.6 278.6c12.5-12.5 12.5-32.8 0-45.3l-128-128c-9.2-9.2-22.9-11.9-34.9-6.9s-19.8 16.6-19.8 29.6l0 256c0 12.9 7.8 24.6 19.8 29.6s25.7 2.2 34.9-6.9l128-128z\"/></svg>');\n",
       "  }\n",
       "\n",
       "  .repr-section-toggle-col\n",
       "    > button:not(.collapsed)\n",
       "    > span.collapse-uncollapse-caret {\n",
       "    background-image: url('data:image/svg+xml;charset=utf8,<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 320 512\"><!--!Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.--><path fill=\"white\" d=\"M137.4 374.6c12.5 12.5 32.8 12.5 45.3 0l128-128c9.2-9.2 11.9-22.9 6.9-34.9s-16.6-19.8-29.6-19.8L32 192c-12.9 0-24.6 7.8-29.6 19.8s-2.2 25.7 6.9 34.9l128 128z\"/></svg>');\n",
       "  }\n",
       "}\n",
       "\n",
       ".channel-names-btn {\n",
       "  padding: 0;\n",
       "  border: none;\n",
       "  background: none;\n",
       "  text-decoration: underline;\n",
       "  text-decoration-style: dashed;\n",
       "  cursor: pointer;\n",
       "  color: #0d6efd;\n",
       "}\n",
       "\n",
       ".channel-names-btn:hover {\n",
       "  color: #0a58ca;\n",
       "}\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "<table class=\"repr table table-hover table-striped table-sm table-responsive small\">\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "<tr class=\"repr-section-header general-a95401e0-e7d3-4e00-80d9-18dd342486a3\"  title=\"Hide section\" \n",
       "    onclick=\"toggleVisibility('general-a95401e0-e7d3-4e00-80d9-18dd342486a3')\">\n",
       "    <th class=\"repr-section-toggle-col\">\n",
       "        <button>\n",
       "            \n",
       "            <span class=\"collapse-uncollapse-caret\"></span>\n",
       "        </button>\n",
       "    </th>\n",
       "    <th colspan=\"2\">\n",
       "        <strong>General</strong>\n",
       "    </th>\n",
       "</tr>\n",
       "\n",
       "<tr class=\"repr-element general-a95401e0-e7d3-4e00-80d9-18dd342486a3 \">\n",
       "    <td class=\"repr-section-toggle-col\"></td>\n",
       "    <td>Filename(s)</td>\n",
       "    <td>\n",
       "        \n",
       "        400MNE.fdt\n",
       "        \n",
       "        \n",
       "    </td>\n",
       "</tr>\n",
       "\n",
       "<tr class=\"repr-element general-a95401e0-e7d3-4e00-80d9-18dd342486a3 \">\n",
       "    <td class=\"repr-section-toggle-col\"></td>\n",
       "    <td>MNE object type</td>\n",
       "    <td>RawEEGLAB</td>\n",
       "</tr>\n",
       "<tr class=\"repr-element general-a95401e0-e7d3-4e00-80d9-18dd342486a3 \">\n",
       "    <td class=\"repr-section-toggle-col\"></td>\n",
       "    <td>Measurement date</td>\n",
       "    \n",
       "    <td>Unknown</td>\n",
       "    \n",
       "</tr>\n",
       "<tr class=\"repr-element general-a95401e0-e7d3-4e00-80d9-18dd342486a3 \">\n",
       "    <td class=\"repr-section-toggle-col\"></td>\n",
       "    <td>Participant</td>\n",
       "    \n",
       "    <td>Unknown</td>\n",
       "    \n",
       "</tr>\n",
       "<tr class=\"repr-element general-a95401e0-e7d3-4e00-80d9-18dd342486a3 \">\n",
       "    <td class=\"repr-section-toggle-col\"></td>\n",
       "    <td>Experimenter</td>\n",
       "    \n",
       "    <td>Unknown</td>\n",
       "    \n",
       "</tr>\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "<tr class=\"repr-section-header acquisition-e82c9a99-486f-46be-bb46-6db39820da45\" \n",
       "    title=\"Hide section\"  onclick=\"toggleVisibility('acquisition-e82c9a99-486f-46be-bb46-6db39820da45')\">\n",
       "    <th class=\"repr-section-toggle-col\">\n",
       "        <button>\n",
       "            \n",
       "            <span class=\"collapse-uncollapse-caret\"></span>\n",
       "        </button>\n",
       "    </th>\n",
       "    <th colspan=\"2\">\n",
       "        <strong>Acquisition</strong>\n",
       "    </th>\n",
       "</tr>\n",
       "\n",
       "<tr class=\"repr-element acquisition-e82c9a99-486f-46be-bb46-6db39820da45 \">\n",
       "    <td class=\"repr-section-toggle-col\"></td>\n",
       "    <td>Duration</td>\n",
       "    <td>00:05:00 (HH:MM:SS)</td>\n",
       "</tr>\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "<tr class=\"repr-element acquisition-e82c9a99-486f-46be-bb46-6db39820da45 \">\n",
       "    <td class=\"repr-section-toggle-col\"></td>\n",
       "    <td>Sampling frequency</td>\n",
       "    <td>1024.00 Hz</td>\n",
       "</tr>\n",
       "\n",
       "\n",
       "<tr class=\"repr-element acquisition-e82c9a99-486f-46be-bb46-6db39820da45 \">\n",
       "    <td class=\"repr-section-toggle-col\"></td>\n",
       "    <td>Time points</td>\n",
       "    <td>307,201</td>\n",
       "</tr>\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "<tr class=\"repr-section-header channels-3a56ca0e-db65-4461-831d-367c8e1579cb\"  title=\"Hide section\" \n",
       "    onclick=\"toggleVisibility('channels-3a56ca0e-db65-4461-831d-367c8e1579cb')\">\n",
       "    <th class=\"repr-section-toggle-col\">\n",
       "        <button>\n",
       "            \n",
       "            <span class=\"collapse-uncollapse-caret\"></span>\n",
       "        </button>\n",
       "    </th>\n",
       "    <th colspan=\"2\">\n",
       "        <strong>Channels</strong>\n",
       "    </th>\n",
       "</tr>\n",
       "\n",
       "\n",
       "<tr class=\"repr-element channels-3a56ca0e-db65-4461-831d-367c8e1579cb \">\n",
       "    <td class=\"repr-section-toggle-col\"></td>\n",
       "    <td>EEG</td>\n",
       "    <td>\n",
       "        <button class=\"channel-names-btn\" onclick=\"alert('Good EEG:\\n\\nFp1, Fpz, Fp2, F7, F3, Fz, F4, F8, FC5, FC1, FC2, FC6, T7, C3, Cz, C4, T8, CP5, CP1, CP2, CP6, P7, P3, Pz, P4, P8, POz, O1, Oz, O2, AF7, AF3, AF4, AF8, F5, F1, F2, F6, FC3, FCz, FC4, C5, C1, C2, C6, CP3, CPz, CP4, P5, P1, P2, P6, PO5, PO3, PO4, PO6, FT7, FT8, TP7, TP8, PO7, PO8')\" title=\"(Click to open in popup)&#13;&#13;Fp1, Fpz, Fp2, F7, F3, Fz, F4, F8, FC5, FC1, FC2, FC6, T7, C3, Cz, C4, T8, CP5, CP1, CP2, CP6, P7, P3, Pz, P4, P8, POz, O1, Oz, O2, AF7, AF3, AF4, AF8, F5, F1, F2, F6, FC3, FCz, FC4, C5, C1, C2, C6, CP3, CPz, CP4, P5, P1, P2, P6, PO5, PO3, PO4, PO6, FT7, FT8, TP7, TP8, PO7, PO8\">\n",
       "            62\n",
       "        </button>\n",
       "\n",
       "        \n",
       "    </td>\n",
       "</tr>\n",
       "\n",
       "\n",
       "<tr class=\"repr-element channels-3a56ca0e-db65-4461-831d-367c8e1579cb \">\n",
       "    <td class=\"repr-section-toggle-col\"></td>\n",
       "    <td>EOG</td>\n",
       "    <td>\n",
       "        <button class=\"channel-names-btn\" onclick=\"alert('Good EOG:\\n\\nBIP1')\" title=\"(Click to open in popup)&#13;&#13;BIP1\">\n",
       "            1\n",
       "        </button>\n",
       "\n",
       "        \n",
       "    </td>\n",
       "</tr>\n",
       "\n",
       "\n",
       "<tr class=\"repr-element channels-3a56ca0e-db65-4461-831d-367c8e1579cb \">\n",
       "    <td class=\"repr-section-toggle-col\"></td>\n",
       "    <td>misc</td>\n",
       "    <td>\n",
       "        <button class=\"channel-names-btn\" onclick=\"alert('Good misc:\\n\\nM1, M2, BIP2, BIP3, BIP4, AUX1, AUX2, AUX3, AUX4')\" title=\"(Click to open in popup)&#13;&#13;M1, M2, BIP2, BIP3, BIP4, AUX1, AUX2, AUX3, AUX4\">\n",
       "            9\n",
       "        </button>\n",
       "\n",
       "        \n",
       "    </td>\n",
       "</tr>\n",
       "\n",
       "\n",
       "<tr class=\"repr-element channels-3a56ca0e-db65-4461-831d-367c8e1579cb \">\n",
       "    <td class=\"repr-section-toggle-col\"></td>\n",
       "    <td>Head & sensor digitization</td>\n",
       "    \n",
       "    <td>75 points</td>\n",
       "    \n",
       "</tr>\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "<tr class=\"repr-section-header filters-b34fbcb7-f490-44a3-9f47-05fd216e1ffa\"  title=\"Hide section\" \n",
       "    onclick=\"toggleVisibility('filters-b34fbcb7-f490-44a3-9f47-05fd216e1ffa')\">\n",
       "    <th class=\"repr-section-toggle-col\">\n",
       "        <button>\n",
       "            \n",
       "            <span class=\"collapse-uncollapse-caret\"></span>\n",
       "        </button>\n",
       "    </th>\n",
       "    <th colspan=\"2\">\n",
       "        <strong>Filters</strong>\n",
       "    </th>\n",
       "</tr>\n",
       "\n",
       "<tr class=\"repr-element filters-b34fbcb7-f490-44a3-9f47-05fd216e1ffa \">\n",
       "    <td class=\"repr-section-toggle-col\"></td>\n",
       "    <td>Highpass</td>\n",
       "    <td>0.00 Hz</td>\n",
       "</tr>\n",
       "\n",
       "\n",
       "<tr class=\"repr-element filters-b34fbcb7-f490-44a3-9f47-05fd216e1ffa \">\n",
       "    <td class=\"repr-section-toggle-col\"></td>\n",
       "    <td>Lowpass</td>\n",
       "    <td>512.00 Hz</td>\n",
       "</tr>\n",
       "\n",
       "\n",
       "</table>"
      ],
      "text/plain": [
       "<RawEEGLAB | 400MNE.fdt, 72 x 307201 (300.0 s), ~85 kB, data not loaded>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mne.io import read_raw_eeglab, read_raw\n",
    "from mne.channels import get_builtin_montages, make_standard_montage\n",
    "raw = read_raw_eeglab(\"../sub400/400MNE.set\")\n",
    "raw = raw.crop(tmin=60, tmax=60+5*60)\n",
    "raw.set_channel_types({\"BIP1\":\"eog\",\"BIP2\":\"misc\",\"BIP3\":\"misc\",\"BIP4\":\"misc\", \"AUX1\":\"misc\",\"AUX2\":\"misc\",\"AUX3\":\"misc\",\"AUX4\":\"misc\", \"M1\":\"misc\", \"M2\":\"misc\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fffd4e0-6c24-4774-8336-9965f6705798",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import Textarea, Text, Label, Button, VBox, HBox, HTML, Image, Tab, Output, Layout\n",
    "from IPython.display import display, clear_output\n",
    "import numpy as np\n",
    "import markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "48cda6bc-e843-43a7-b9f4-b72483168b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer_to_reveal(text, answer, with_input_field=False):\n",
    "    test_reveal_button = Button(description=\"Check answer\")\n",
    "    \n",
    "    test_answer = HTML(answer)\n",
    "    test_answer.layout.visibility=\"hidden\"\n",
    "    def show_answer(b):\n",
    "        test_answer.layout.visibility=\"visible\"\n",
    "    test_reveal_button.on_click(show_answer)\n",
    "    layout = Layout(width=\"50%\", border=\"solid purple\")\n",
    "    if with_input_field:\n",
    "        elements = VBox([HTML(text), HBox([Text(), test_reveal_button]), test_answer], layout=layout)\n",
    "    else:\n",
    "        elements = VBox([HTML(text), HBox([test_reveal_button]), test_answer], layout=layout)\n",
    "    return elements\n",
    "    \n",
    "def get_chapter(panels, panel_titles):\n",
    "    tab = Tab()\n",
    "    tab.children = panels\n",
    "    tab.titles = panel_titles\n",
    "    chapter = tab\n",
    "    return chapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ee50d5be-c9ea-4e64-b76f-0d3b9f16eb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def code_block(code):\n",
    "    text = f\"\"\"\n",
    "    <style>\n",
    "      pre {{\n",
    "        background-color: #f5f5f5;\n",
    "        padding: 10px;\n",
    "        border-radius: 5px;\n",
    "        overflow-x: auto;\n",
    "      }}\n",
    "      code {{\n",
    "        font-family: monospace;\n",
    "        color: #333;\n",
    "    }}\n",
    "    </style>\n",
    "    <pre><code>\n",
    "    {code}\n",
    "    </code></pre>\n",
    "    \"\"\"\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "864bb715-9273-4fd1-8a1b-04912de72de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_data(d):\n",
    "    ch_names = d.ch_names\n",
    "    assert type(ch_names) == list and len(ch_names) > 0\n",
    "    assert raw.n_times > 60\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990d5f63-14d1-4141-87b6-23b1c3b43c8a",
   "metadata": {},
   "source": [
    "# Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4a7d9380-b543-49bf-8e66-2a638ea508fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "937c8e172bc9483b8c9cc2afb3c11344",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(HTML(value=\"\\nWelcome! \\nThis tutorial has two purposes\\n<br>\\n<b>First</b>, it teaches you to w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw = None\n",
    "\n",
    "text = \"\"\"\n",
    "Welcome! \n",
    "This tutorial has two purposes\n",
    "<br>\n",
    "<b>First</b>, it teaches you to work with EEG data with explanations and visualizations. \n",
    "<br>\n",
    "<b>Second</b>, it allows you to explore your own data along the explanations, to directly apply your new knowledge. This tutorial can best be used, if you have an EEG dataset at hand. \n",
    "If you have one, you will read the data in the following. You don't need to know anything about the data yet. You will learn it during this course. \n",
    "If you don't have any dataset, you can still continue with the tutorial. You will be missing some interactions and tests, but you can still read all the texts and learn. \n",
    "\n",
    "\"\"\"\n",
    "panel_1 = HTML(text)\n",
    "\n",
    "text = \"\"\"\n",
    "Do you have an EEG dataset?\n",
    "\"\"\"\n",
    "output = Output()\n",
    "output_2 = Output()\n",
    "yes_button = Button(description=\"yes\")\n",
    "no_button = Button(description=\"No\")\n",
    "def no(b):\n",
    "    text = \"Okay. Just continue with the next panel.\"\n",
    "    with output:\n",
    "        display(HTML(text))\n",
    "        \n",
    "def read_data(path):\n",
    "    global raw\n",
    "    raw = read_raw(path)\n",
    "    raw = raw.crop(tmin=60, tmax=60+5*60)\n",
    "    raw.set_channel_types({\"BIP1\":\"eog\",\"BIP2\":\"misc\",\"BIP3\":\"misc\",\"BIP4\":\"misc\", \"AUX1\":\"misc\",\"AUX2\":\"misc\",\"AUX3\":\"misc\",\"AUX4\":\"misc\", \"M1\":\"misc\", \"M2\":\"misc\"})\n",
    "\n",
    "\n",
    "def yes(b):\n",
    "    input_text = Text()\n",
    "\n",
    "    def display_read_data(b):\n",
    "        path = input_text.value\n",
    "        try:\n",
    "            read_data(path)\n",
    "            try:\n",
    "                check_data_plausibility(raw)\n",
    "            except AssertionError as e:\n",
    "                with output_2:\n",
    "                    clear_output()\n",
    "                    display(HTML(\"The data has been read, but it does not look plausible. Are you sure that this is the correct file? You can continue with it, but it might fail at a later stage.\"))\n",
    "            with output_2:\n",
    "                clear_output()\n",
    "                display(HTML(\"The file has been read succesfully. You can continue!\"))\n",
    "        except Exception as e:\n",
    "            with output_2:\n",
    "                clear_output()\n",
    "                display(HTML(\"There was a problem with this file: <br>\" + str(e)))\n",
    "    \n",
    "    text = \"Great! Past the path to your datafile here:\"\n",
    "    read_in_button = Button(description=\"Read Data\")\n",
    "    read_in_button.on_click(display_read_data)\n",
    "    \n",
    "    with output:\n",
    "        clear_output()\n",
    "        display(VBox([HTML(text), input_text, read_in_button]))\n",
    "    \n",
    "no_button.on_click(no)\n",
    "yes_button.on_click(yes)\n",
    "panel_2 = VBox([HTML(text), HBox([yes_button, no_button]), output, output_2])\n",
    "\n",
    "\n",
    "code = code_block(\"\"\"\n",
    "x = mne.call_function(x)\n",
    "\"\"\")\n",
    "text = f\"\"\"\n",
    "Within this course, we will use a python-library called MNE-python from time to time. \n",
    "MNE-python provides lots of functions you can use to work with EEG data. \n",
    "When we use some code from MNE, it will be displayed like this: \n",
    "{code}\n",
    "\n",
    "This is not a full tutorial on MNE though. If you want to learn more about MNE, you can browse their tutorials by clicking <a href=\"https://mne.tools/stable/documentation/index.html\"><u>here</u></a>.\n",
    "If you don't care about coding and using MNE, you can also ignore the code examples. You will still be able to understand what is happening.\n",
    "\"\"\"\n",
    "\n",
    "panel_3 = HTML(text)\n",
    "\n",
    "text = \"\"\"\n",
    "The course is structured as follows:\n",
    "<ul>\n",
    "<li>Chapters (1) and (2) explain how an EEG works and how the data recorded with an EEG looks like. </li>\n",
    "<li>Chapters (3) to (5) go into more detail an how periodic signals can be described and analyzed in general. These chapter are not EEG-specific. </li>\n",
    "<li>Chapter (6) describes the EEG signal using the learnings from (3) to (5). </li>\n",
    "<li> Chapter (7) introduces the power spectrum, which is a more sophisticated way to analyze and understand EEG data.</li>\n",
    "</ul>\n",
    "\"\"\"\n",
    "panel_4 = HTML(text)\n",
    "\n",
    "chapter = get_chapter([panel_1, panel_2, panel_3, panel_4], [\"1\",\"2\",\"3\", \"4\"])\n",
    "display(chapter) #../sub400/400MNE.set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8f3f72-7cc1-4378-b2a6-4f0156687e76",
   "metadata": {},
   "source": [
    "# (1) What is an EEG?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fd76fca0-ec12-4700-913d-52c62cced374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1302cfc027c94c7392bdf3bfd591dc56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(VBox(children=(HTML(value='\\nWhat is an EEG at all? EEG stands for Electroencephalography. \"Ence…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "What is an EEG at all? EEG stands for Electroencephalography. \"Encephalon\" is the greek word for brain and \"graphein\" means writing. Accordingly, an EEG is a device that writes electric brain signals.\n",
    "You may already know, that the brain sends electric signals along the neurons' axons. There are plenty of neurons and they send many tiny signals per second. If researchers want to measure these signals on the basis of single neurons, they cut open the head and implement tiny measurement tools. \n",
    "This is done in animals most often, because human's don't want their head to be cut open. \n",
    "The EEG however, doesn't need any operation beforehand, which is why we call it a non-invasive method. You can easily imagine that this makes it much more accessible for research. You just need to place an eeg cap on the participants head that may look like this:\n",
    "\"\"\"\n",
    "im_eeg_hood = Image(value=open(\"resources/EEG_cap.jpg\", \"rb\").read(),width=200,height=250)\n",
    "panel_1 = VBox([HTML(text), im_eeg_hood])\n",
    "\n",
    "\n",
    "text = \"\"\"\n",
    "I already mentioned, that the EEG measures electric signals of neurons, and it does that from outside of the skull. \n",
    "If a single neurons sends an electric signal, we would never be able to record this from the outside of the skull, though, because it would be way too small. \n",
    "However, if many neurons send electric signals at the same time, they sum up and this can be measured from the outside with sensitive electrodes. This is what the EEG does. \n",
    "It is important to understand, that the EEG doesn't record <i>all</i> the brain activity but just the very strong highlights. \n",
    "Imagine you are standing outside of a soccer arena. You don't see the game, you just hear the fans' voices. Would you be able to understand everyting that happens within the game?\n",
    "Most likely not. But you would be able to recognize major events like a scored goal, because here all fan's (or half of them) cheer altogether. \n",
    "Transferred to the brain, these are the kinds of signals an EEG measures. \n",
    "\"\"\"\n",
    "panel_2 = HTML(text)\n",
    "\n",
    "text = \"\"\"\n",
    "On the picture shown before you may have recognized, that an EEG cap includes multiple electrodes at different locations. \n",
    "The brain has a very sophisticated structure and different parts of it are responsible for different functions. \n",
    "For example (and strongly simplified), the back part of the prain (the so-called occpital region) is associated with processing visual information, while the frontal part is responsible for deliberate and conscious thought. \n",
    "Due to that structure, it makes sense to place electrodes at different locations on the skull to measure these differences. \n",
    "On top of that, multiple electrodes alow to measure a signal more reliably. Single electrodes will always have lots of noise in their measurement (we will discuss this later in more detail). \n",
    "If you take more electrodes, their noise will be different but the underlying signal will be caught by all of them (to a different extend) and this allows you, to extract this signal more easily. \n",
    "\"\"\"\n",
    "panel_3 = HTML(text)\n",
    "\n",
    "text = \"\"\"\n",
    "How many electrodes does an EEG have at all and where exactly are they located? \n",
    "There is not <i>the one and only</i> eeg cap, but there are different standards on the number and location of electrodes. \n",
    "The format used most often is known as 10-20-system. In the following you see a visualization of the electrodes.\n",
    "\"\"\"\n",
    "im_10_20 = Image(value=open(\"resources/10_20.png\", \"rb\").read(),width=400,height=600)\n",
    "text_2 = \"\"\"\n",
    "Do you see the nose at the top (Nasion) and the ears to the left and right? The person in the image looks upwards and you look at their head from above. \n",
    "You see that the electrodes all have names like NZ, PO3 or P9. When you look at the data later, you want to know which electrode captures which signal, and this is why you want to be familiar with the naming scheme.\n",
    "The first letter(s) indicate the region of the brain the electrode is placed on: pre-frontal (Fp), frontal (F), temporal (T), parietal (P), occipital (O) and central (C). \n",
    "This indicates the position on the axis from nose to back of the head. \n",
    "On top of that, there is information on the location of the axis from ear to ear. Electrodes with a \"Z\" are placed in the middle of the brain. \n",
    "Electrodes with even numbers are placed on the right part of the head, while electrodes with uneven numbers are on the left part. \n",
    "For example, FZ is frontal and in the middle. P4 is parietal and on the right part. C3 is central and on the left part of the brain. \n",
    "You also see two electrodes \"A1\" and \"A2\" placed behind the ear. Sometimes they are also called \"M1\" and \"M2\" instead. \n",
    "In some picture there are also two points NZ and IZ. These are <b>no</b> electrodes, but just points of reference, that are used, when the EEG cap is placed on a person's skull. \n",
    "While they may appear on such visualizations, you will never find EEG data recorded from electrodes called NZ or IZ. \n",
    "\"\"\"\n",
    "panel_4 = VBox([HTML(text), im_10_20, HTML(text_2)])\n",
    "\n",
    "text = \"\"\"\n",
    "The 10-20 system we just saw had 21 electrodes in total. \n",
    "However, sometimes you don't need that much, or you need even more. Hence, different standards exist with a different numbers of electrodes. \n",
    "Often you may see the 10-10 system, which is an extension of the 10-20 system. If you observe it carefully, you will see that it includes all the electrodes of the 10-20 system, extended by some more:\n",
    "\"\"\"\n",
    "im_10_10 = Image(value=open(\"resources/10_10.png\", \"rb\").read(),width=400,height=600)\n",
    "\n",
    "text_2 = \"\"\"\n",
    "Other EEG caps may use less electrodes like the 14 ones here:\n",
    "\"\"\"\n",
    "im_14 = Image(value=open(\"resources/14_channel_eeg.png\", \"rb\").read(),width=400,height=600)\n",
    "\n",
    "text_3 = \"\"\"\n",
    "When working with EEGs, it is important to decide on the number of electrodes before, depending on the equipment available and the research's demands. \n",
    "Even more important is to know which system has been used when interpreting the data, though. \n",
    "When you analyze EEG signals (as we will do in this tutorial later), you need to know how many electrodes recorded them and where exactly these electrodes have been placed. \n",
    "\"\"\"\n",
    "panel_5 = VBox([HTML(text), im_10_10, HTML(text_2), im_14])\n",
    "\n",
    "montages = get_builtin_montages()\n",
    "montages = \"<br>\".join(montages)\n",
    "channels = np.random.choice(raw.ch_names, size=min(6, len(raw.ch_names)))\n",
    "code = code_block(\"\"\"\n",
    "raw.set_montage(make_standard_montage(\"standard_1020\"))\n",
    "raw.plot_sensors(ch_type=\"eeg\")\n",
    "\"\"\")\n",
    "text = f\"\"\"\n",
    "MNE comes with a list of builtin channel systems (also called \"montages\") that are the following:\n",
    "<br>\n",
    "{montages}\n",
    "\n",
    "Let's assume your data is missing the information on which system has been used exactly. However, you still have the channel names and from these, the system may be inferred. \n",
    "Here are some channels of your data:\n",
    "{channels}\n",
    "Can you already guess, which system has been used?\n",
    "MNE also provides a function to apply a selected montage to a dataset. \n",
    "{code}\n",
    "Try it with one of the montages listed above!\n",
    "Can you find the right montage for your data?\n",
    "What happens, if you use a montage that doesn't fit? \n",
    "\"\"\"\n",
    "text_input = Text()\n",
    "def try_out_montage(name=None):\n",
    "    if name is None:\n",
    "        name = text_input.value\n",
    "    try:\n",
    "        x = raw.copy()\n",
    "        x.set_montage(make_standard_montage(name))\n",
    "        return x.plot_sensors(ch_type=\"eeg\", show=False)\n",
    "    except Exception as e:\n",
    "        return str(e)\n",
    "output = Output()\n",
    "def display_montage(b):\n",
    "    montage = try_out_montage()\n",
    "    with output:\n",
    "        clear_output()\n",
    "        display(montage)\n",
    "button = Button(description=\"Apply Montage\")\n",
    "button.on_click(display_montage)\n",
    "\n",
    "panel_6 = VBox([HTML(text), text_input, button, output])\n",
    "\n",
    "chapter = get_chapter([panel_1, panel_2, panel_3, panel_4, panel_5, panel_6], [\"1\",\"2\",\"3\",\"4\", \"5\", \"Try it yourself!\"])\n",
    "display(chapter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4484e6-e07b-4542-a4fa-9e5359f02642",
   "metadata": {},
   "source": [
    "# (2) EEG Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ad35c213-349a-4c56-99e9-c08c9a4db1fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3b06b2ecc334d8987a337c319aa2319",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(VBox(children=(HTML(value='\\nWe now know what an EEG is. Next it is time to take a look at the d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%matplotlib widget\n",
    "\n",
    "text = \"\"\"\n",
    "We now know what an EEG is. Next it is time to take a look at the data that is collected with an EEG. Most of the time, you will see the data being displayed like this: \n",
    "\"\"\"\n",
    "\n",
    "im_eeg = Image(value=open(\"resources/eeg_raw_signal.png\", \"rb\").read(),width=400,height=600)\n",
    "\n",
    "text_2 = \"\"\"\n",
    "First of all, you see multiple lines of data here. These are channels and corespond to the different electordes you are already familiar with. You see the electrode/channel names on the left.\n",
    "You also see, that the data is ploted over time on the x-axis. \n",
    "With an eeg, you don't just record brain activity at a given point in time, but you record it over a longer time. \n",
    "The y-axis displays a notion of strength of a signal. We will discuss this in a later chapter in more detail. \n",
    "For now, you should become familiar with the idea, that there are multiple channels with a signal varying over time each.\n",
    "\"\"\"\n",
    "\n",
    "panel_1 = VBox([HTML(text), im_eeg, HTML(text_2)])\n",
    "\n",
    "text = \"\"\"This is how your data looks like.\n",
    "Note that you can interact with this visualization. You can click on the bars on the x and y axis to jump to different points in time or different channels.\n",
    "Do the signals differ between the channels? Are there channels that stand out in particular?\n",
    "Can you use your knowledge about the electrodes' locations to explain some of these differences?\"\"\"\n",
    "\n",
    "output = Output()\n",
    "with output:\n",
    "    raw.plot(n_channels=4)\n",
    "\n",
    "panel_2 = VBox([HTML(text), output])\n",
    "\n",
    "chapter = get_chapter([panel_1, panel_2], [\"1\",\"Try it yourself!\"])\n",
    "display(chapter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c8dc18-7cd4-4e9d-aeaf-4400a4db79e3",
   "metadata": {},
   "source": [
    "# (3) What is a periodic signal?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "be85248d-4973-4078-b263-c6795b70e320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cbc685152534721b52127fcb7434cc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(VBox(children=(HTML(value='\\nWe have taken a first look at EEG data in the previous chapter. \\nN…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "width, height = 600, 800\n",
    "\n",
    "im_string_moving = Image(value=open(\"resources/string_moving.gif\", \"rb\").read(),width=width,height=height)\n",
    "\n",
    "text = \"\"\"\n",
    "We have taken a first look at EEG data in the previous chapter. \n",
    "Now we want to understand it in more detail. To this end, we first need to take a step back and talk about what periodic signals are in general. \n",
    "In many applications you have processes that are repeating. For example, if you pull the string of a guitar and let it go, this string will move back and forth in a periodic manner.\n",
    "Here is a visualization. The string starts at the top (a), then it moves back to the middle (e) and continues moving in the opposite direction (i). \n",
    "Then it moves back to the middle again (m) and back to the position it started from (p and ultimatively a). From here it moves to the middle again and so on. \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "text_2 = \"\"\"\n",
    "Now imagine you are able to measure the position of middle point of the string at different points in time during this process. \n",
    "Let's say the maximum displacement of the spring towards the top (as in (a)) is indicated by a value of 1 and the middle position of the string (e) is a 0.\n",
    "If we plot the time on the x-axis and the displacement on the y-axis, this would look like this: \n",
    "\"\"\"\n",
    "\n",
    "x = [(1/2)*np.pi, (3/4)*np.pi, np.pi, (5/4)*np.pi, (3/2)*np.pi, (7/4)*np.pi, 2*np.pi]\n",
    "y = np.sin(x)\n",
    "fig,ax = plt.subplots()\n",
    "ax.set_xticks(x, labels=[\"a\", \"c\", \"e\", \"g\", \"i\", \"k\", \"m\"])\n",
    "ax.scatter(x,y, color=\"black\")\n",
    "fig.set_size_inches(4,2)\n",
    "output = Output()\n",
    "with output:\n",
    "    display(fig)\n",
    "\n",
    "text_3 = \"\"\"\n",
    "If we do this more frequently and with smaller timesteps in between, the curve looks more smooth:\n",
    "\"\"\"\n",
    "\n",
    "output2 = Output()\n",
    "x = np.arange((1/2)*np.pi, 2*np.pi, 0.1)\n",
    "y = np.sin(x)\n",
    "fig,ax = plt.subplots()\n",
    "ax.scatter(x,y, color=\"black\")\n",
    "fig.set_size_inches(4,2)\n",
    "with output2:\n",
    "    display(fig)\n",
    "\n",
    "panel_1 = VBox([HTML(text), im_string_moving, HTML(text_2), output, HTML(text_3), output2])\n",
    "\n",
    "text = \"\"\"\n",
    "Now we saw a moving string turn into a signal. This was possible, because it's movemenet was periodic, i.e. recurring over time. \n",
    "Likewise, brain activity can be periodic. Say you measure the activity over time and see that it goes up and down again and again. \n",
    "Can you imagine that such a signal would look like this?\n",
    "\"\"\"\n",
    "output = Output()\n",
    "x = np.arange((1/2)*np.pi, 12*np.pi, 0.1)\n",
    "y = np.sin(x)\n",
    "fig,ax = plt.subplots()\n",
    "ax.plot(x,y, color=\"black\")\n",
    "fig.set_size_inches(4,2)\n",
    "with output:\n",
    "    display(fig)\n",
    "panel_2 = VBox([HTML(text), output])\n",
    "\n",
    "chapter = get_chapter([panel_1, panel_2], [\"1\", \"2\"])\n",
    "display(chapter)\n",
    "\n",
    "#https://www.phys.unsw.edu.au/jw/strings.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62b425b-174a-454c-a4a1-6b6a7e40e814",
   "metadata": {},
   "source": [
    "# (4) Signal Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "618e8277-de11-4ca9-80bd-41b84575d884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34d7f23753ab46ce87c6f391ace8fc8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(HTML(value='\\nIn the previous chapter we understood what a signal is and why brain activity can …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "im_1_5 = Image(value=open(\"resources/amp_1_freq_5.png\", \"rb\").read(),width=width,height=height)\n",
    "im_1_25 = Image(value=open(\"resources/amp_1_freq_25.png\", \"rb\").read(),width=width,height=height)\n",
    "im_7_5 = Image(value=open(\"resources/amp_7_freq_5.png\", \"rb\").read(),width=width,height=height)\n",
    "im_7_25 = Image(value=open(\"resources/amp_7_freq_25.png\", \"rb\").read(),width=width,height=height)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "text1 = \"\"\"\n",
    "In the previous chapter we understood what a signal is and why brain activity can be interpreted as such. \n",
    "We now want to discuss some properties that describe signals that are the <b>Frequency</b> and the <b>Amplitude</b>.\n",
    "<br>\n",
    "The <b>frequency</b> indicates, how often a signal oscillates, i.e., how often it goes up and down in a given time-range. We measure the frequency in Hertz (Hz), which can be understood as the number of ups and downs per second. \n",
    "A frequency of 50Hz means 50 ups and downs in one second. \n",
    "You can use the frequency to describe different processes that repeat over time. For example, you heart beats ~60 times a minute, which is a frequency of 0.016Hz. \n",
    "If you play the A-key on a piano, the string and the air it puts into motion will oscilate with a frequency of 440Hz. If you play a higher note, the frequency increases and with lower notes, the frequency decreases. \n",
    "Electromagentic waves have frequencys as well. Red light has a frequency of 400THz (terra herz, that is 10¹² herz) and X-rays have a frequency around 10¹⁸ Hz. \n",
    "\"\"\"\n",
    "\n",
    "panel_1 = HTML(text1)\n",
    "\n",
    "text = \"\"\"\n",
    "As mentioned, the frequency in Hz is the number of oscilations per second. In the following you see two signals. \n",
    "\"\"\"\n",
    "answer_text = \"\"\"\n",
    "The left signal has a frequency of 5 Hz. You can find out by counting how often the signal does a full oscilation from 0 (where it starts), up to 1, down to -1 and back to 0.\n",
    "You could also count the number of mountains (+1) or valleys (-1) in 1 second. \n",
    "The right signal has a higher frequency of 25 Hz. \n",
    "\"\"\"\n",
    "answer = get_answer_to_reveal(\"Can you tell, which frequencies they have?\", answer_text)\n",
    "panel_2 = VBox([HTML(text), HBox([im_1_5, im_1_25]), answer])\n",
    "\n",
    "text = \"\"\"\n",
    "The <b>amplitude</b> tells you, how much a signal goes up and down in one cycle. \n",
    "In the following you see two plots of same frequency but with different amplitudes. Do you see, that the one covers a range from -1 to +1 on the y-axis, but the other covers a bigger range from -7 to +7?\n",
    "The first signal has an amplitude of 1, the second has an amplitude of 7. \n",
    "\"\"\"\n",
    "text_2 = \"\"\"\n",
    "The amplitude of a signal is related to its power (which will be explained later in more detail). If you play a sound on an instrument, higher amplitude means a louder sound. \n",
    "A signal with too much power could even destroy your ear. \n",
    "\"\"\"\n",
    "panel_3 = VBox([HTML(text), HBox([im_1_5,im_7_5]), HTML(text_2)])\n",
    "\n",
    "im_4_15 = Image(value=open(\"resources/amp_4_freq_15.png\", \"rb\").read(),width=width,height=height)\n",
    "text = \"\"\"\n",
    "Test yourself!\n",
    "\"\"\"\n",
    "answer = get_answer_to_reveal(\"What is the frequency and the amplitude of this signal?\", \"Amplitude: 4 (because the signal goes from -4 to 4 on the y-axis). Frequency: 15 (because there are 15 ups and downs within one second).\")\n",
    "panel_4 = VBox([HTML(text), im_4_15, answer])\n",
    "\n",
    "chapter = get_chapter([panel_1, panel_2, panel_3, panel_4], [\"1\",\"2\", \"3\", \"Test yourself!\"])\n",
    "display(chapter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4209a6e4-3f0f-4a7e-8a9c-e2e50c167e49",
   "metadata": {},
   "source": [
    "# (5) Sampling Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "fe9c9be6-23a6-4548-826a-6b00160e87d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a84eae7ca0a41f8b8915e053bc7ba7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(VBox(children=(HTML(value='Say we have a signal that looks like this.'), Image(value=b'\\x89PNG\\r…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "file = open(\"resources/10_hz_signal.png\", \"rb\")\n",
    "\n",
    "\n",
    "\n",
    "text1 = \"Say we have a signal that looks like this.\"\n",
    "im_signal = Image(value=open(\"resources/10_hz_signal.png\", \"rb\").read(),width=width,height=height)\n",
    "panel_1 = VBox([HTML(text1), im_signal])\n",
    "\n",
    "text2 = \"We now sample this signal, i.e., we measure it's vaue at different points in time. These points in time we see as orange dots here. All the points have equal distance on the x-axis. If we do that often enough, we can connect the dots and get the signal.\"\n",
    "im_signal_sampled = Image(value=open(\"resources/10_hz_signal_sampled.png\", \"rb\").read(),width=width,height=height)\n",
    "panel_2 = VBox([HTML(text2), im_signal_sampled])\n",
    "\n",
    "text3 = \"However, what would happen, if we use very few points only? Take a look at the following example. Again, these points all have the same distance on the x-axis. However, they don't allow to capture the full range of the signal. If we connect them, we get a signal (flat orange line) that is very different from the one, we wanted to sample.\"\n",
    "im_signal_sampled_incorrectly_1 = Image(value=open(\"resources/10_hz_signal_sampled_incorrectly_1.png\", \"rb\").read(),width=width,height=height)\n",
    "panel_3 = VBox([HTML(text3), im_signal_sampled_incorrectly_1])\n",
    "\n",
    "text4 = \"It would be very bad luck, if all our points catch the exact same value of the signal, as in the previous example. However, if the number of points is too small, we can end up with arbitrary signals, that just don't reflect the signal we are sampling from\"\n",
    "im_signal_sampled_incorrectly_2 = Image(value=open(\"resources/10_hz_signal_sampled_incorrectly_2.png\", \"rb\").read(),width=width,height=height)\n",
    "panel_4 = VBox([HTML(text4), im_signal_sampled_incorrectly_2])\n",
    "\n",
    "text_explanation = \"We just saw, that having too feq sampling points can be problematic. The number of sampling points in a given time-range is called the sampling frequency. E.g., if we collect 10 points per second, this is a sampling frequency of 10Hz. \\n If we have a signal of n Hz, the sampling frequency must be at least 2*n Hz to capture the signal. This is called the Nyquist Frequency. The other way round, if you sample with a frequency of n Hz, you can not expect to capture signals that have a frequency of more than n/2 Hz.\"\n",
    "panel_5 = HTML(text_explanation)\n",
    "\n",
    "\n",
    "output = Output()\n",
    "def sample(sampling_freq=50):\n",
    "    x = np.arange(0, 1, 0.001)\n",
    "    # create a 20hz signal\n",
    "    y = np.sin(20*x*2*np.pi)\n",
    "    x_sample = np.arange(0,1, 1/sampling_freq)\n",
    "    # sample the 20hz signal with the given sampling_freq\n",
    "    sample = np.sin(20*x_sample*2*np.pi)\n",
    "    \n",
    "    fig,axs = plt.subplots(1,2,sharex=True, sharey=True)\n",
    "    axs[0].plot(x,y, color=\"black\")\n",
    "    axs[0].scatter(x_sample, sample, color=\"orange\")\n",
    "    axs[1].plot(x_sample, sample, color=\"orange\")\n",
    "    fig.set_size_inches(14,6)\n",
    "    return fig\n",
    "\n",
    "def show_sampling_plot(b,sampling_freq=None):\n",
    "    if sampling_freq is None:\n",
    "        sampling_freq = int(input_freq.value)\n",
    "    fig = sample(sampling_freq)\n",
    "    \n",
    "    with output:\n",
    "        clear_output()\n",
    "        display(fig)\n",
    "    print(\"this\")\n",
    "\n",
    "show_sampling_plot(None, sampling_freq=50)\n",
    "text = \"You can try it yourself! The signal you see here has a frequency of 20Hz. What happens if you sample it with lower or higher frequencies?\"\n",
    "input_freq = Text(placeholder=\"50\")\n",
    "button = Button(description=\"Sample\")\n",
    "button.on_click(show_sampling_plot)\n",
    "panel_6 = VBox([HTML(text), HBox([input_freq, button]), output])\n",
    "\n",
    "\n",
    "test_input_field = Text()\n",
    "answer = get_answer_to_reveal(\"You are sampling a signal with a frequency of 80Hz. What is the maximum frequency you can expect in the signal you construct from the sampling points?\", \"40 Hz\")\n",
    "panel_7 = HBox([test_input_field, answer])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "chapter = get_chapter([panel_1, panel_2, panel_3, panel_4, panel_5, panel_6, panel_7], [\"1\",\"2\",\"3\",\"4\", \"Explanation\", \"Try it yourself\", \"Test yourself!\"])\n",
    "\n",
    "display(chapter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900ce854-3967-462d-8094-ee64da702425",
   "metadata": {},
   "source": [
    "# (6) EEG bandwidths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "72bc1fd0-cb70-4b67-8939-95bfbd8f174b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "763edcbcb3ac46e6a240c4d2d5a751ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(HTML(value='In the following, we will learn what are typical frequencies for EEG data. We will s…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#https://nhahealth.com/brainwaves-the-language/\n",
    "# https://www.researchgate.net/publication/275830679_A_New_EEG_Acquisition_Protocol_for_Biometric_Identification_Using_Eye_Blinking_Signals?_tp=eyJjb250ZXh0Ijp7ImZpcnN0UGFnZSI6Il9kaXJlY3QiLCJwYWdlIjoiX2RpcmVjdCJ9fQ\n",
    "\n",
    "text = \"In the following, we will learn what are typical frequencies for EEG data. We will see that there are different bandwidths, that are associated with different kinds of brain activity.\"\n",
    "panel_1 = HTML(text)\n",
    "\n",
    "text = \"\"\"\n",
    "What range of frequencies do EEG waves occur in? We already saw, that signals in general can vary from very fast (X-rays in petaherz range) to very slow (your pulse with ~1 Hz). \n",
    "The brain does not cover this whole spectrum. One can say, that brain activity is limited to the range of roughly 0.5 to 100Hz.\n",
    "As a convention, EEG signals are sub-divided into five different bandwiths Alhpa, Beta, Gamma, Delta and Theta, which include different frequencies. The main reason for this sub-division is, that these bandwidths are associated with different kinds of activity:\n",
    "<p><b>Delta</b> (less than 4Hz) <br> Delta waves have the lowest frequency and occur during sleep.</p>\n",
    "<p><b>Theta</b> (4-8 Hz) <br> Theta waves appear somewhere in the border between sleep and an awake state. If you daydreaming or doing medidation, theta waves may increase.</p>\n",
    "<p><b>Alpha</b> (8-12Hz) <br> Alpha waves reflect a state of alertnes and being prepared to act. However, they are associated with a rather relaxed state and not so much with concentrating deliberately.</p>\n",
    "<p><b>Beta</b> (13-30Hz) <br> When you are awake and have your eyes open, Beta waves occur. They are associated with conscious activities such as listening or thinking concrentratedly.</p>\n",
    "<p><b>Gamma</b> (greater than 30 Hz) <br> The fast Gamma waves appear, when you need to process multiple sources of information in parallel.</p>\n",
    "\n",
    "You can learn more about bandwiths <a href=\"https://nhahealth.com/brainwaves-the-language/\" target=\"_blank\">here</a>\n",
    "\n",
    "\"\"\"\n",
    "panel_2 = HTML(text)\n",
    "\n",
    "text = \"This is how the bandwidths look like in an EEG signal. Do you agree, that Gamma waves have the highest, and Delta waves have the lowest frequency? Do you think you can specify the correct bandwidth for a given signal? If so, go to the next tab!\"\n",
    "image_source = \"\"\"<a href=\"https://www.researchgate.net/publication/275830679_A_New_EEG_Acquisition_Protocol_for_Biometric_Identification_Using_Eye_Blinking_Signals?_tp=eyJjb250ZXh0Ijp7ImZpcnN0UGFnZSI6Il9kaXJlY3QiLCJwYWdlIjoiX2RpcmVjdCJ9fQ\" target=\"_blank\">Image source</a>\"\"\"\n",
    "im_frequency_bands = Image(value=open(\"resources/frequency_bands_eeg.png\", \"rb\").read(),width=width,height=height)\n",
    "panel_3 = VBox([HTML(text), im_frequency_bands, HTML(image_source)])\n",
    "\n",
    "text = \"Here are two signals. What bandwidths do they belong to?\"\n",
    "panel_4 = HTML(text)\n",
    "\n",
    "chapter = get_chapter([panel_1, panel_2, panel_3, panel_4], [\"1\",\"2\", \"3\", \"Test yourself!\"])\n",
    "display(chapter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4fbfbc-e7c4-4106-b499-3e1176e5f8a2",
   "metadata": {},
   "source": [
    "# (7) Power Spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4615140d-53b8-4c51-8d6e-ea3eae9320a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective window size : 2.000 (s)\n",
      "Plotting power spectral density (dB=True).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15627/3220567632.py:45: RuntimeWarning: Channel locations not available. Disabling spatial colors.\n",
      "  psd_plot = psd.plot(show=False)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2c28909c1834eaab66ef99f652eda23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(VBox(children=(HTML(value='In this chapter, we will introduce the Power Spectrum, which is a use…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "#https://neuroimage.usc.edu/forums/t/eeg-power-spectral-density/3634\n",
    "\n",
    "text = \"\"\"In this chapter, we will introduce the Power Spectrum, which is a usefull way to display properties of an EEG signal. \n",
    "For the power spectrum, we have the frequency on the x-axis and the Power on the y-axis. The power is derived from the squared amplitude of the signal. What does that mean? \n",
    "You can understand the amplitude as a measure of the energy. The higher the amplitude, the more energy a signal has. You can easily recognize this, when you hear music. A higher amplitude means a louder sound and that is more energy. \n",
    "You don't need to care why exactly we have to square the amplitude (this is just physics), but be aware that squaring a high amplitude also leads to high power.\n",
    "Summing up, the power is a measure of \"how much energy\" is in a signal. When we plot this power over the frequency, we get an idea, which different components an EEG signal consists of.\n",
    "<br>\n",
    "Let's take a look at such a power spectrum.\n",
    "\"\"\"\n",
    "\n",
    "im_power_spectrum = Image(value=open(\"resources/power_spectrum.png\", \"rb\").read(),width=width,height=height)\n",
    "text_2 = \"\"\"\n",
    "Do you see, that there is quite a high power around 10Hz? Looks like the 10Hz waves are contributing more to the overall signal than the 20Hz waves, for example.\n",
    "If you watched the figure carefully, you may have noticed, that the y-axis is not micro-volt squared, but micro-volt squared divided by Hz. This is done to obtain better comparibilty between the different bandwidths. \n",
    "Naturally, waves with higher frequencies contain more energy, which would make it unfair to compare a wave of, say 50Hz with one of 1Hz directly. Dividing by the frequency mitigates this problem. \n",
    "If we divide the micro-volt squared by the frequency, we call this a <b>Power Spectrum Density (PSD)</b>. <br>\n",
    "Sometimes you may also see the y-axis of a power spectrum (density) to be in decibel (db). This is just another way of scaling the power to compare different magnitudes of power more easily.\n",
    "You can still interpret the plots the same way though: Higher values mean more power. \n",
    "\"\"\"\n",
    "\n",
    "panel_1 = VBox([HTML(text), im_power_spectrum, HTML(text_2)])\n",
    "\n",
    "text = \"\"\"Remember the bandwidths we saw in the previous chapter? With the power spectrum, it is quite easy to identify which frequencies are present in an EEG signal. Different areas on the x-axis belong to the different bandwidths.\"\"\"\n",
    "im_sleep_eeg = Image(value=open(\"resources/sleep_eeg.png\", \"rb\").read(),width=width,height=height)\n",
    "im_band_power = Image(value=open(\"resources/band_power.png\", \"rb\").read(),width=width,height=height)\n",
    "text_2 = \"\"\"\n",
    " If you see which bandwidth are dominant, you can already get an idea of what the person is doing.\n",
    " In the following you see EEGs for people that are awake (top left) or sleeping (remaining three images). Do you see how the alpha waves are spiking in the awake state but decline in the sleep states?\n",
    "Which channels are more prominent during sleep? Does that match what you learned about the bandwidths in the previous chapter?\n",
    "\"\"\"\n",
    "\n",
    "panel_2 = VBox([HTML(text), im_band_power, HTML(text_2), im_sleep_eeg])\n",
    "\n",
    "\n",
    "text = \"The power spectrum can be plotted for each channel individually or as an average over each channel.\"\n",
    "answer = get_answer_to_reveal(\"Can you guess, what could be an advantage of showing it for each channel?\", \"If you display each channel, you can detect if some channels behave different than others. There are different reasons for that, but one could be, that a channel captures elictric signals that are not coming from the brain but are noise we don't want.\")\n",
    "panel_3 = VBox([HTML(text), answer])\n",
    "\n",
    "\n",
    "text = \"Take a look at the power spectrum of your own data. Do you observe anything interesting? Is the power rising or falling for higher frequencies? Are there any frequencies that are dominant?\"\n",
    "psd = raw.compute_psd(fmax=120)\n",
    "psd_plot = psd.plot(show=False)\n",
    "output = Output()\n",
    "with output:\n",
    "    display(psd_plot)\n",
    "panel_4 = VBox([HTML(text),output])\n",
    "\n",
    "chapter = get_chapter([panel_1, panel_2, panel_3, panel_4], [\"1\",\"2\", \"3\", \"Check your own data\"])\n",
    "display(chapter)\n",
    "\n",
    "#https://link.springer.com/article/10.1007/s11571-020-09639-w\n",
    "#https://www.researchgate.net/publication/346510774_Criticality_and_the_role_of_the_connectome_in_shaping_slow_oscillations_in_the_brain_during_deep_sleep?_tp=eyJjb250ZXh0Ijp7ImZpcnN0UGFnZSI6Il9kaXJlY3QiLCJwYWdlIjoiX2RpcmVjdCJ9fQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb43f6ed-294e-44a0-9302-5ade8c975694",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (eeg)",
   "language": "python",
   "name": "eeg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
